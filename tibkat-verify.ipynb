{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_community.graphs.age_graph import AGEGraph\n",
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "import psycopg2\n",
    "import getpass\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "\n",
    "database = {\n",
    "    \"database\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"password\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGEGraph.refresh_schema = lambda self: None\n",
    "\n",
    "graph = AGEGraph(graph_name=\"gnd\", conf=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    dbname=database[\"database\"],\n",
    "    user=database[\"user\"],\n",
    "    password=database[\"password\"],\n",
    "    host=database[\"host\"],\n",
    "    port=database[\"port\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6980"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents: list[Document] = []\n",
    "\n",
    "for dirs, _, f in os.walk(\"llms4subjects/shared-task-datasets/TIBKAT/tib-core-subjects/data/dev/\"):\n",
    "    for file in f:\n",
    "        with open(os.path.join(dirs, file)) as f:\n",
    "            data = json.load(f)[\"@graph\"]\n",
    "            subjects = []\n",
    "            article = None\n",
    "            document = Document(page_content=\"\", metadata={})\n",
    "            for d in data:\n",
    "                if \"@type\" in d:\n",
    "                    document = Document(\n",
    "                        page_content=str(d[\"abstract\"]).replace(\"\\\"\", \"'\"),\n",
    "                        metadata={\n",
    "                            \"subjects\": []\n",
    "                        },\n",
    "                        id=d[\"@id\"]\n",
    "                    )\n",
    "                    if type(d[\"title\"]) == str:\n",
    "                        document.metadata[\"title\"] = d[\"title\"].replace(\"\\\"\", \"'\")\n",
    "                    elif type(d[\"title\"]) == list:\n",
    "                        document.metadata[\"title\"] = d[\"title\"][0].replace(\"\\\"\", \"'\")\n",
    "                else:\n",
    "                    if type(d[\"sameAs\"]) == str:\n",
    "                        subjects.append(d[\"sameAs\"].replace(\"\\\"\", \"'\"))\n",
    "                    elif type(d[\"sameAs\"]) == list:\n",
    "                        for s in d[\"sameAs\"]:\n",
    "                            subjects.append(s.replace(\"\\\"\", \"'\"))\n",
    "            document.metadata[\"subjects\"] = subjects\n",
    "            documents.append(document)\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAPI token: \")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"tibkat-core-dev.pkl\"):\n",
    "    document_embeddings: List[List[float]] = embeddings.embed_documents([d.page_content for d in documents])\n",
    "    pickle.dump(document_embeddings, open(\"tibkat-core-dev.pkl\", \"wb\"))\n",
    "else:\n",
    "    document_embeddings: List[List[float]] = pickle.load(open(\"tibkat-core-dev.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"tibkat\",\n",
    "    connection=f\"postgresql+psycopg2://{database['user']}:{database['password']}@{database['host']}:{database['port']}/{database['database']}\",\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_subjects': [{'s': {'classification_name': 'Methoden und Techniken '\n",
      "                                                      'der empirischen '\n",
      "                                                      'Sozialforschung, '\n",
      "                                                      'Statistik in den '\n",
      "                                                      'Sozialwissenschaften, '\n",
      "                                                      'Mathematische Statistik',\n",
      "                               'code': 'gnd:4153917-5'}},\n",
      "                        {'s': {'classification_name': 'Erkenntnistheorie, '\n",
      "                                                      'Logik',\n",
      "                               'code': 'gnd:4280370-6'}},\n",
      "                        {'s': {'classification_name': 'Erkenntnistheorie, '\n",
      "                                                      'Logik',\n",
      "                               'code': 'gnd:4426693-5'}},\n",
      "                        {'s': {'classification_name': 'Stochastik, Operations '\n",
      "                                                      'Research',\n",
      "                               'code': 'gnd:4252658-9'}},\n",
      "                        {'s': {'classification_name': 'MikroÃ¶konomie, '\n",
      "                                                      'Wettbewerb',\n",
      "                               'code': 'gnd:4171190-7'}},\n",
      "                        {'s': {'classification_name': 'Mathematische Methoden, '\n",
      "                                                      'Information, '\n",
      "                                                      'Entscheidung',\n",
      "                               'code': 'gnd:4056243-8'}}],\n",
      " 'real_subjects': [{'s': {'classification_name': 'Erkenntnistheorie, Logik',\n",
      "                          'code': 'gnd:4139716-2'}},\n",
      "                   {'s': {'classification_name': 'Wirtschaft, Volkswirtschaft '\n",
      "                                                 '(Allgemeines)',\n",
      "                          'code': 'gnd:4066528-8'}},\n",
      "                   {'s': {'classification_name': 'Volkswirtschaft',\n",
      "                          'code': 'gnd:4252654-1'}},\n",
      "                   {'s': {'classification_name': 'Volkswirtschaft',\n",
      "                          'code': 'gnd:4124477-1'}},\n",
      "                   {'s': {'classification_name': 'Natur, Naturwissenschaften '\n",
      "                                                 'allgemein',\n",
      "                          'code': 'gnd:4015999-1'}}],\n",
      " 'title': '4. Games'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "for document, embedding in zip(documents, document_embeddings):\n",
    "    similar = vector_store.similarity_search_by_vector(embedding, k=10)\n",
    "    similar_document_subjects = list(set(itertools.chain(*[similar.metadata.get(\"subjects\", []) for similar in similar])))\n",
    "    subject_names = graph.query(f\"\"\"\n",
    "    MATCH (s:Subject)-[:ALTERNATIVE_NAME]->(an:AlternativeName), (s2:Subject)-[:RELATED]->(s), (s2:Subject)-[:ALTERNATIVE_NAME]->(an2)\n",
    "    WHERE an.name IN {json.dumps(similar_document_subjects)}\n",
    "    RETURN an2\n",
    "    \"\"\")\n",
    "    filtered_subject_names = [s['an2']['name'] for s in subject_names]\n",
    "\n",
    "    llm_query = f\"\"\"\n",
    "    You are an AI that has been trained on a large corpus of scientific articles. You have been asked to provide a list of subjects that are related to the following article: `{document.metadata['title']}`. The article is about `{document.page_content}`. The subjects that can be related to this article are: {filtered_subject_names}. Do not include any subjects that are not related to the article. Do not generate any new subjects. Use the subjects that are already in the database. Print the list of subjects as a JSON object. Print the list of subjects in the same way that they are presented. DO NOT translate them. Do not print anything else, just the list of subjects as a JSON object. Do not capitalize `subjects`.\n",
    "\n",
    "    The subjects that are related to this article are:\n",
    "    \"\"\"\n",
    "\n",
    "    json_schema = {\n",
    "        \"title\": \"subjects\",\n",
    "        \"description\": \"The subjects that are related to the article\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"subjects\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"The subjects that are related to the article\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"subjects\"],\n",
    "    }\n",
    "\n",
    "    llm.with_structured_output(json_schema)\n",
    "    response = llm.invoke(llm_query)\n",
    "    try:\n",
    "        filtered_subjects = json.loads(response.content)[\"subjects\"]\n",
    "    except json.JSONDecodeError:\n",
    "        print(response.content)\n",
    "        continue\n",
    "\n",
    "    subjects_codes = graph.query(f\"\"\"\n",
    "    MATCH (s:Subject)-[:ALTERNATIVE_NAME]-(an:AlternativeName)\n",
    "    WHERE an.name IN {json.dumps(filtered_subjects)}\n",
    "    RETURN s\n",
    "    \"\"\")\n",
    "\n",
    "    real_subjects = graph.query(f\"\"\"\n",
    "        MATCH (s:Subject)-[:ALTERNATIVE_NAME]-(an:AlternativeName)\n",
    "        WHERE an.name IN {json.dumps(document.metadata['subjects'])}\n",
    "        RETURN s\n",
    "    \"\"\")\n",
    "\n",
    "    pprint.pprint({\n",
    "        \"title\": document.metadata[\"title\"],\n",
    "        \"real_subjects\": real_subjects,\n",
    "        \"predicted_subjects\": subjects_codes\n",
    "    })\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    MATCH (s:Subject)-[:ALTERNATIVE_NAME]->(an:AlternativeName)\n",
    "    WHERE an.name = 'Methodologie'\n",
    "    RETURN s\n",
    "\"\"\"\n",
    "\n",
    "graph.query(query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fii-advrn-project-OBGXxNtN-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
